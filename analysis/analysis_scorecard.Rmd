---
title: "analysis"
author: "Brad Stirling"
date: "2022-07-30"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r}
library(multcomp)
library(fixest)
library(tidyverse)
```

```{r}
load("processed_data/processed_scorecard.RData")
```

## Introduction and Data Cleaning Overview

This analysis explores the impact of the publication of the college scorecard on consumer interest in bachelor's degree-granting educational institutions. Specifically, it examines its relationship with the 10-year post graduate median earnings. The goal was to see if the scorecard shifted interest from schools with low post-graduate earnings to schools with high ones. In addition to post graduate earnings, the analysis explored controls across institution types, average student age, percentage of STEM programs, SAT averages, and median debt.

Consumer interest was measured by looking at the average shift in standardized Google search rankings following the publication of the scorecard in September 2015. As the Google trends data had 7 months of post-scorecard observations, the table was filtered to 14 total months for the analysis. To account for the seasonality of the college application deadlines, the 7-month pre-scorecard timeframe was September 2014 to March 2015. Thus the analysis compared September 2014 through March 2015 to September 2015 to March 2016. An additional binary variable was created to categorize pre and post scorecard implementation groups. 

The search rankings were then standardized for each school name and keyword. A histogram of the resulting standardized rankings showed a fairly normal-looking distribution. The data set was then grouped by school and scorecard implementation category, and mean standardized rankings were calculated for the pre and post scorecard launch periods per school. The means were then un-pivoted into separate columns for pre and post ranking means, and the difference between the pre and post ranking means were calculated. This resulted in a trends table with a single row for each school, with corresponding scorecard-period standardized ranking means, and the post-scorecard ranking shift. The post-scorecard ranking shift was used as the outcome variable of the regression models.

Next, the scorecard data set was filtered to only predominantly bachelor's degree-granting schools. Variables that were identified as potential controls, such as institution type, program emphasis, test scores, age, and debt were converted into either decimals or factors for regression testing. Following the initial clean up, the school id link table was filtered to remove duplicate schools with duplicate names, and then inner-joined to both the scorecard and the summarized school-level trend data.

To determine the categorization of high-earning vs low-earning schools, the quantile function was used on the median-earnings 10 years post-graduation variable. Schools that had values less than the 25% quantile (35,500) were labeled as low, while schools greater than the 75% quantile (48,100). The data set was then filtered to remove the other values, and the high-earning vs low-earning variable was re-categorized as binary, with a value of 1 indicating a high-earning school. The high-earning school binary category was used as the treatment variable of the regression models.

## Data Exploration

Following the initial data cleaning and creation of the treatment and outcome variables, control variables identified from the data dictionary were further explored as potential sources of endogeneity. 

```{r, echo=FALSE}
scorecard_f %>% ggplot(aes(x = `med_earnings_10yrs`)) + 
  geom_histogram(bins = 100) +
  ggtitle("College Graduate Median Earnings 10 Years Post-Graduation: High vs. Low") +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(x = "Median Earnings",
       y = "") + 
  scale_x_continuous(labels = scales::dollar_format())
  
```
```{r}
scorecard_f %>% filter(med_earnings_10yrs > 100000) %>% arrange(desc(med_earnings_10yrs))
```

The histogram of the median earnings per school was skewed right for higher-earning schools. After subsetting the scorecard to schools with median earnings greater than $100K, it was observed that their graduates were all in STEM fields.To address this in the model, the STEM degree percentage categories were summed, and a binary variable was added, separating out schools with STEM graduates greater than 50%. The STEM control was considered a bias source as it could have affected both the high earning category and the shift in search rankings. STEM fields typically pay much higher than other careers, thus positively impacting median earnings for schools with heavy concentrations of these graduates. Additionally, STEM fields were already gaining popularity at the time the scorecard was released, and interest in STEM-focused schools could have been less impacted by its release as it would have been common knowledge to consumers. This category was ultimately not used in the model as it would have resulted in washing out variation from our treatment variable. By removing STEM fields from the High-earning category, it would just been comparing the students who didn't graduate in these programs.


```{r}
sat_nulls <- sum(is.na(scorecard_f$SAT_AVG))
sprintf("Missing SAT score rows: %s", sat_nulls)
```

Average SAT scores were also explored but were not used in the model. Though it could have affected the high-income category, with students who test well being more goal-driven and thus seeking out higher paying jobs after graduation, it would not have impacted the search rankings. Additionally, the high number of missing observations would have removed too much data from the analysis.

```{r}
scorecard_f %>% group_by(institution_type) %>% summarize(count = n())
```

Institution type (private for profit, private non-profit, and public) was identified for inclusion as a fixed effect variable as they have many characteristics that don’t change over time and could cause endogeneity. Private universities are typically more expensive than public universities, which could also control for average grad school debt, cost, percentage of Pell loans, and percentage of federal loans. As the price of the school would already have been known prior to the publication of the scorecard, students who were interested in these schools could be more driven to seek out higher paying careers after graduation to offset the expense. Like the STEM-field categorization, the interest for technical degrees was already growing, and thus the increased search interest in high-earning colleges existed independent of the scorecard publication. 

The final variable that was selected to control for endogeneity was the percentage of undergraduates aged 25 or older. Older graduates could have multiple characteristics that could bias the treatment variable and the search rankings. They could have more focused career goals resulting in greater financial success after graduation. Their additional work experience prior to attending college could lead to higher incomes afterward as they would already have stronger resumes than younger graduates. As this group of students could have spent more time researching and preparing for schools, it’s likely they would have had more knowledge about higher-earning colleges, and thus their search behavior would not have been influenced by the scorecard release.  

## Model Analysis

```{r}
m1 <- scorecard_f %>% feols(ind_z_shift ~ high_earning, se = "hetero")
etable(m1)
```

An initial model was created as a baseline, regressing the standardized post-scorecard search ranking shift on the high-earning treatment. The model showed that low-earnings schools saw an increase in average search rankings of -0.21 standard deviations following the introduction of the scorecard. Note: as the rankings were on a low to high scale starting at 1, a decrease is interpreted as increase. High-earning schools were linearly associated with an additional -0.15 standard deviation increase in search rankings post scorecard. Both the intercept and the treatment were statistically significant at an alpha of 0.001, meaning that if the null hypothesis were true, we would only get results like these in 0.1% of the samples.

```{r}
m1_5 <- scorecard_f %>% feols(ind_z_shift ~ high_earning | institution_type)
m2 <- scorecard_f %>% feols(ind_z_shift ~ high_earning | institution_type, se = "hetero")

etable(m1, m1_5, m2)

```

Next, institution type was added as fixed effects variable. Models with both cluster-robust and heteroskedasticity-robust standard errors were created. Due to the large amount of variance in institution type, the heteroskedasticity model was kept. The addition of this variable caused the effect of the high-earning coefficient to drop to -0.10, meaning controlling for the other variables in the model, high-earning schools saw an increase of -0.10 search ranking standard deviations in addition to low-earning schools, following the release of the scorecard. Also, 2% of the variation in the search-ranking shift was explained by the within variation in the high-earning treatment, while 31% of the total variation in the model was explained by the within variation and the institution type. 

```{r}
m3 <- scorecard_f %>% feols(ind_z_shift ~ high_earning + UG25abv | institution_type, se = "hetero")

etable(m1, m2, m3)

```

Following the addition of the fixed effects variable, the percentage of students aged 25 or older was added. Adjusting for other variables in the model, a 1 unit increase in the percentage of the 25+ aged students resulted in a search rank increase of -0.51 standard deviations. The impact of high-earning schools was in line with the earlier model, with interest via search trend standard deviations -0.1 higher than low-earning schools. The overall variation explained in the model rose to 37% with 10% explained by the within variation in the high-earning and percentage of 25+ aged students.

```{r, echo=FALSE}
scorecard_f %>% ggplot(aes(UG25abv, ind_z_shift)) + 
  geom_point() + 
  geom_smooth(method = "lm") +
  ggtitle("Google Trend Rankings Post Scorecard Publication on Student Age Population") +
  xlab("Percentage of students 25 or older") + 
  ylab("Standard Deviations") +
  scale_x_continuous(labels = scales::percent_format())

```

```{r}
m4 <- scorecard_f %>% feols(ind_z_shift ~ high_earning + UG25abv + high_earning * UG25abv| institution_type, se = "hetero")

etable(m1, m2, m3, m4)
glht(m4, "high_earning + high_earning:UG25abv = 0") %>% summary()

```

An interaction between the high-earning category and the percentage of 25+ aged students was included after reviewing the plot of student percentage and post-scorecard implementation ranking shift, as it appeared that a shift in the slope could potentially decrease the size of the residuals of the linear regression line. Holding all over variables constant, high-earning schools saw an increase in ranking post-scorecard implementation of -0.04 standard deviations, with an additional increase of -0.2 standard deviations when the percentage of 25+ aged students increased by 1 unit. As the result of the general linear hypothesis test was statistically significant at a 1% alpha, it was concluded that the interaction did not explain additional variation, and thus was dropped from the model.


```{r}
m5 <- scorecard_f %>% feols(ind_z_shift ~ high_earning + UG25abv + GRAD_DEBT_MDN_SUPP| institution_type, se = "hetero")

etable(m1, m2, m3, m5)

```

As a final step, the median debt of graduates was added to see if it had an effect outside of the fixed effects of the institution type. The result showed that holding all other variables constant, a one unit increase in debt increased search ranking post scorecard by 0.000008 standard deviations. Given its minimal impact on the model, it was also dropped from the model.

## Conclusion

```{r}

etable(m3)

```

After reviewing the results of each regression, it was determined that the strongest model controlled for percentage of students 25 years or older, and the institution type. Thus, it can be concluded, that following the release of the scorecard, high-earning colleges had larger shift in rankings relative to lower earning ones. The model shows that holding all other variables constant, high-earning colleges saw an additional -0.1 increase in standardized search rankings post-publication above their lower-earning counterparts.
